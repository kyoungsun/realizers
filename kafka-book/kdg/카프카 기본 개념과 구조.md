# 카프카의 기본 구성요소
<hr>

#### 주키퍼 

- 분산 애플리케이션이 안정적인 서비스를 할 수 있도록 도와주는 코디네이션 시스템입니다.
- 주키퍼가 다운되면 분산 애플리케이션 전체가 다운될 수 있으므로 안정성을 확보하기 위해 클러스터로 구축합니다.
- 주키퍼에는 카프카(브로커)의 메타 데이터나 브로커의 헬스 체크를 담당합니다.

#### 카프카(브로커)

- 메시지(레코드)를 관리하는 서버, 여러대의 브로커로 클러스터링할 수 있습니다.

#### 프로듀서

- 메시지를 발송하는 서버

#### 컨슈머

- 메시지를 소비하는 서버

#### 토픽

- 프로튜서와 컨슈머가 소통하는 창구의 역할을 수행합니다.
- 토픽의 이름은 카프카내에서 유니크해야합니다.

#### 파티션

- 하나의 토픽내에 물리적으로 나뉜 영역입니다.
- 카프카는 파티션을 통해 강력한 병렬 처리 및 고성능을 얻을 수 있습니다.

#### 세그먼트

- 프로듀서가 전송한 메시지가 브로커의 로컬 디스크에 저장되는 파일입니다.

![스크린샷 2024-01-26 오후 10 08 36](https://github.com/kdg0209/realizers/assets/80187200/d1709322-71e1-44fa-83ae-ff7eded17c74)

#### 메시지(레코드)

- 프로듀서가 브로커로 데이터를 전송하거나, 컨슈머가 읽어가는 데이터 조각입니다.

<br>

# 리플리케이션
<hr>

- 아래 명령어는 test-m-topic 토픽을 생성하며 파티션의 수는 3개, 리플리케이션은 3개를 유지하겠다는 명령어입니다.
- Isr을 보면 현재 동기화되고 있는 리플리케이션 정보를 확인할 수 있습니다.
- Replicas를 보면 현재 파티션이 복제되고 있는 브로커의 정보를 확인할 수 있습니다.
- Leader는 프로듀서, 컨슈머로부터 오는 읽기와 쓰기 요청을 처리하며, Follower는 오직 Leader로부터 리플리케이션하게 됩니다.
```
1. kafka-topics --bootstrap-server localhost:9092 --create --topic test-m-topic --partitions 3 --replication-factor 3
2. kafka-topics --bootstrap-server localhost:9092 --describe --topic test-m-topic
```
![스크린샷 2024-01-26 오후 10 58 42](https://github.com/kdg0209/realizers/assets/80187200/874291d6-fd6f-498c-904a-10250b090568)

![스크린샷 2024-01-26 오후 11 30 29](https://github.com/kdg0209/realizers/assets/80187200/48aeb0e7-6bd8-4369-83af-47762b1419ef)

<br>

#### 🤔 멀티 브로커 환경에서 replication-factor 옵션을 주지 않고 토픽을 만들면 어떻게 될까?

- Replicas, Isr의 정보를 토대로 파티션이 복제되거나, 동기화 중인 브로커가 없습니다.
```
1. kafka-topics --bootstrap-server localhost:9092 --create --topic test-2-m-topic --partitions 2
2. kafka-topics --bootstrap-server localhost:9092 --describe --topic test-2-m-topic
```

![스크린샷 2024-01-26 오후 11 16 11](https://github.com/kdg0209/realizers/assets/80187200/14b0831a-3824-4a3e-986e-d90cd754fd1d)

<br>

# 파티션
<hr>

- 하나의 토픽이 한번에 처리할 수 있는 한계를 높이기 위해 하나의 토픽을 여러개의 물리적 영역으로 나눈것을 파티션이라 합니다.
- 파티션 수는 초기 생성시 얼마든지 늘릴 수 있지만, 반대로 늘린 파티션은 다시 줄일 수 없기 때문에 신중해야 합니다.
- 처음 파티션수를 적게 가져가고, 컨슈머의 메시지 처리량을 모니터링하면서 조금씩 늘려가는 방법이 좋습니다.
  - 컨슈머의 LAG로 파악합니다.(프로듀서가 보낸 메시지 수 - 컨슈머가 가져간 메시지 수)

<br>

# 세그먼트
<hr>

- 세그먼트란 프로듀서가 전송한 메시지가 로컬 디스크에 저장되는 파일입니다. 0X20.log
- ⭐️ 참고: Key가 없는 메시지는 파티션이 여러개인 경우 순서보장을 할 수 없음. 
```
// 메시지 프로듀서 
1. kafka-console-producer --bootstrap-server localhost:9092 --topic test-m-topic --property key.separator=: --property parse.key=true

// 메시지 컨슈머
2. kafka-console-consumer --bootstrap-server localhost:9092 --topic test-m-topic --property print.key=true --property print.value=true --property print.partition=true --from-beginning

// 세그먼트 조회
3. kafka-dump-log --deep-iteration --files 00000000000000000000.log --print-data-log
```

![스크린샷 2024-01-26 오후 11 53 47](https://github.com/kdg0209/realizers/assets/80187200/2053ede0-a981-45fc-8b65-11d18b7174c1)

<br>

# 분산 시스템에서 모든 브로커 서버가 죽으면?
<hr>

- 카프카 클러스터내에 브로커 1, 2, 3이 있었는데 초록색 메시지를 Leader/Follower에게 모두 전달하였고, 5초 뒤에 브로커 3이 다운되어 카프카 클러스터내에는 브로커 1, 2만 남아있게 되었습니다.
  
![스크린샷 2024-01-27 오전 12 19 09](https://github.com/kdg0209/realizers/assets/80187200/48ee8886-639f-496b-bd3c-aec97e5f6192)

- 시간이 흘러 파란색 메시지를 Leader/Follower에게 모두 전달하였고, 3초 뒤에 브로커 2가 다운되어 카프카 클러스터내에는 브로커 1만 남아있게 되었습니다.

![스크린샷 2024-01-27 오전 12 23 04](https://github.com/kdg0209/realizers/assets/80187200/137d1b8e-5a91-400b-bac0-93e5016cf89d)

- 또 시간이 흘러 자주색 메시지를 Leader에게만 전달이 되었습니다. 그리고 1초 후에 Leader 브로커 마져 다운이 되어 카프카 클러스터내에는 실행중인 브로커가 없게되는데 이때 2가지 대응을 할 수 있습니다.

![스크린샷 2024-01-27 오전 12 25 05](https://github.com/kdg0209/realizers/assets/80187200/ddcf7849-23c4-4141-8cbf-9d8b0d776420)


### 💡 대응 방법

1. 마지막까지 Leader였던 브로커 1이 다시 실행되고, Leader가 될 때까지 기다립니다.
2. Leader/Follower 상관없이 가장 먼저 실행되는 브로커가 리더가 됩니다.
3. ⭐️ 참고: 카프카는 기본 설정으로 2번 방법을 사용합니다.

#### 1번 방법

- 1번 방법을 사용한다면 데이터 손실이 가장 적으나, 무조건 브로커 1이 먼저 실행되어야하는 조건이 있습니다. 만약 브로커 1이 결함이 생겨 바로 실행되지 않는다면 더 큰 문제로 이어질 수 있습니다.

#### 2번 방법

- 2번 방법은 가장 빨리 장애에 대응가능하지만 데이터 손실이 가장 크게 발생합니다.

<br>

# Page Cache
<hr>

### 순차 I/O

- 디스크에 순차적으로 접근하는 순차 I/O는 Random Access에 비해 150,000배 빠르다고 합니다.
- 세그먼트 파일의 자료 구조는 메시지가 중간에 삽입되지 않고, 오로지 끝에만 저장되는 append-only의 특성을 가지고 있습니다.
- 세그먼트에 쓰여진 메시지(레코드)는 수정이 불가합니다.
- 카프카는 Zero-Copy를 사용함으로써 context-switch의 발생 횟수를 줄이고, 성능을 개선하였습니다.
  - https://velog.io/@jinii/%EC%A0%9C%EB%A1%9C%EC%B9%B4%ED%94%BCzero-copy

![스크린샷 2024-01-27 오전 11 01 22](https://github.com/kdg0209/realizers/assets/80187200/e85df68d-3081-44c1-a0ef-b8a7f9f11513)

<br>

# 배치 전송 및 압축 전송
<hr>

- 프로듀서에서 send 메서드 호출 시 KafkaProducer.class의 send 메서드를 호출하게 됩니다.
- 내부에서 Serializer가 수행되어 압축이 되며, 파티셔닝이 이루어집니다.
- 그리고 RecordAccumulrator 클래스의 append 메서드가 호출되며 배치로 담기게 됩니다.
- 그리고 별개의 Sender 스레드는 RecordAccumulator에 배치로 저장된 데이터를 drain 메서드로 꺼내 kafka cluster로 데이터를 전송하는 역할을 수행합니다.(Sender.class 내부적으로 이루어짐)

![스크린샷 2024-01-27 오후 12 58 07](https://github.com/kdg0209/realizers/assets/80187200/172adbd2-4e43-43d4-a2a9-361e39941be6)

<br>

# Producer
<hr>

- Producer는 메시지를 매번 브로커에게 전송하는게 아니라 배치 단위로 전송하게 됩니다. (RecordAccumulator)
- 프로듀서의 옵션값 중에서 buffer.memory 옵션을 사용하여 브로커로 데이터를 보내기전에 어느정도 담겨야 보낼지 설정할 수 있습니다. (기본값: 33554432)
- linger.ms 옵션을 통해 buffer.memory의 설정값 만큼 가득차지 않아도 메시지를 보낼 수 있게됩니다.
- 만약 linger.ms보다 낮은 시간에 buffer.memory가 가득찼다면 바로 메시지를 브로커에게 전달하게 됩니다.

  
### 메시지 보내고 확인하지 않기

- 실제 운영환경에서 추천하지 않지만, 카프카는 항상 살아 있고 프로듀서 또한 자동으로 재시작하므로 대부분은 성공적으로 메시지를 발송할 수 있습니다.

```java
public class Producer {

    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String TOPIC_NAME = "welcome-topic";

    public static void main(String[] args) {
        var properties = new Properties();
        properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

        try {
            for (int i = 0; i < 5; i++) {
                String key = "user" + i;
                String value = "message " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, key, value);
                kafkaProducer.send(record);
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            kafkaProducer.close();
        }
    }
}
```
![스크린샷 2024-01-27 오후 1 32 55](https://github.com/kdg0209/realizers/assets/80187200/9012c6fc-4a4e-4f34-b567-9b0bb2a75076)

### 동기 전송

- 메시지 전송의 신뢰성은 얻을 수 있지만 보낸 메시지에 응답을 기다려야하므로 많은 시간을 소비하게 되고 빠른 전송을 할 수 없습니다.
  
```java
public class Producer {

    public static final Logger LOGGER = LoggerFactory.getLogger(Producer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String TOPIC_NAME = "welcome-topic";

    public static void main(String[] args) {
        var properties = new Properties();
        properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

        try {
            for (int i = 0; i < 5; i++) {
                String key = "user" + i;
                String value = "message " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, key, value);
                RecordMetadata metadata = kafkaProducer.send(record).get();

                LOGGER.info("topic: {}, partition: {}, offset: {}",
                        metadata.topic(),
                        metadata.partition(),
                        metadata.offset());
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            kafkaProducer.close();
        }
    }
}

```

### 비동기 전송

- 빠른 전송이 가능하고, 메시지 전송이 실패한 경우 콜백으로 대처를 할 수 있습니다.

```java
public class Producer {

    public static final Logger LOGGER = LoggerFactory.getLogger(Producer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String TOPIC_NAME = "welcome-topic";

    public static void main(String[] args) {
        var properties = new Properties();
        properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

        try {
            for (int i = 0; i < 5; i++) {
                String key = "user" + i;
                String value = "message " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, key, value);
                kafkaProducer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        LOGGER.info("topic: {}, partition: {}, offset: {}", metadata.topic(), metadata.partition(), metadata.offset());
                    }
                });
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            kafkaProducer.close();
        }
    }
}
```

<br>

# Consumer
<hr>

- 컨슈머는 반드시 컨슈머 그룹에 속하게 됩니다.
- 컨슈머 그룹이란 하나 이상의 컨슈머들이 모여있는 그룹을 의미합니다.
- 이상적인 컨슈머 수는 파티션 수와 일대일 매칭되는게 이상적입니다.

### Auto Commit 방식

- auto commit은 기본값으로 가장 많이 사용됩니다.
- auto commit은 오프셋을 주기적으로 커밋하므로 관리자가 오프셋을 따로 관리하지 않아도 되는 장점이 있지만, 컨슈머가 빈번히 종료되면 일부 메시지를 못 가져오거나, 중복 메시지를 소비할 수 있습니다.

```java
public class Consumer {

    public static final Logger LOGGER = LoggerFactory.getLogger(Consumer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String GROUP_NAME = "welcome-group";
    private static final String TOPIC_NAME = "welcome-topic";

    public static void main(String[] args) {

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_NAME);

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of(TOPIC_NAME));

        // poll
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));

            for (ConsumerRecord<String, String> record : records) {
                LOGGER.info("topic: {}, partition: {}, offset: {}, key: {}, value: {}", record.topic(), record.partition(), record.offset(), record.key(), record.value());
            }
        }
    }
}
```

### Sync 방식

```java
public class Consumer {

    public static final Logger LOGGER = LoggerFactory.getLogger(Consumer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String GROUP_NAME = "welcome-group";
    private static final String TOPIC_NAME = "welcome-topic";

    public static void main(String[] args) {

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_NAME);

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of(TOPIC_NAME));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));

                for (ConsumerRecord<String, String> record : records) {
                    LOGGER.info("topic: {}, partition: {}, offset: {}, key: {}, value: {}", record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }
                
               try {
                   if (records.count() > 0) {
                       consumer.commitSync();
                   }
               } catch (CommitFailedException e) {
                   e.printStackTrace();
               }
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            consumer.close();
        }
    }
}
```

### Async 방식

```java
public class Consumer {

    public static final Logger LOGGER = LoggerFactory.getLogger(Consumer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String GROUP_NAME = "welcome-group";
    private static final String TOPIC_NAME = "welcome-topic";

    public static void main(String[] args) {

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_NAME);

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of(TOPIC_NAME));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));

                for (ConsumerRecord<String, String> record : records) {
                    LOGGER.info("topic: {}, partition: {}, offset: {}, key: {}, value: {}", record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }
                consumer.commitAsync((offsets, exception) -> {
                    if (exception != null) {
                        LOGGER.error("offsets: {} is not completed, error: {}", offsets, exception);
                    } else {
                        for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {
                            LOGGER.info("topic: {}, partition: {}, offset: {}, metadata: {}", entry.getKey().topic(), entry.getKey().partition(), entry.getValue().offset(), entry.getValue().metadata());
                        }
                    }
                });
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            consumer.close();
        }
    }
}
```

<br>

# 리밸런싱을 위해 hook 설정한 Consumer
<hr>

```
// 파티션 3개인 토픽 생성
1. kafka-topics --bootstrap-server localhost:9092 --create --topic multi-partition-topic --partitions 3

2. 로컬 PC에서 하나의 Producer 서버와 3개의 Consumer 서버 가동
```

#### Producer 서버는 메시지를 3개의 파티션으로 보냄

- 아래 로그를 보면 3개의 파티션으로 메시지가 발송되는것을 볼 수 있습니다.

<img width="966" alt="스크린샷 2024-01-28 오후 1 43 48" src="https://github.com/kdg0209/realizers/assets/80187200/c87f9ae9-2beb-4e07-8046-b180423ac095">

#### 하나의 Consumer서버만 가동

- 아래 사진은 하나의 Consumer 서버만 가동을 시켰고, partition 3개를 소비하고 있는 것을 확인할 수 있습니다.

<img width="965" alt="스크린샷 2024-01-28 오후 1 46 14" src="https://github.com/kdg0209/realizers/assets/80187200/f5725a5b-e523-43a1-ac7a-73aeb5538f27">

#### 하나의 Consumer 서버를 추가적으로 가동

- 컨슈머 그룹에서 리밸런싱이 일어나 새로 추가된 Consumer 서버도 파티션 2를 할당받아 소비하는 것을 확인할 수 있습니다.

<img width="1019" alt="스크린샷 2024-01-28 오후 1 51 29" src="https://github.com/kdg0209/realizers/assets/80187200/6326dc03-caa9-4aa0-8d69-6d1f754ee1ad">

#### 마지막 하나의 Consumer 서버를 추가적으로 가동

- 이렇게 리밸런싱 과정을 통해 총 3개의 Consumer가 가동이 되는것까지 확인을 하였고, 이제부터 Consumer 서버가 다운될때마다 어떻게 되는지 살펴보겠습니다.

<img width="1021" alt="스크린샷 2024-01-28 오후 1 56 41" src="https://github.com/kdg0209/realizers/assets/80187200/21ffec59-1c69-4b70-b02d-15e0caf7d453">

### 하나의 Consumer 서버를 중지

- 하나의 Consumer 서버를 중지시켰다.
- 하지만 리밸런싱은 즉시 동작하지 않습니다.

<img width="995" alt="스크린샷 2024-01-28 오후 2 03 55" src="https://github.com/kdg0209/realizers/assets/80187200/c81bfa17-8cd9-41fa-91d3-5cf010698c81">

### Consumer 코드 수정

```java
public class Consumer {

    private static final Logger LOGGER = LoggerFactory.getLogger(Consumer.class.getName());
    private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:9092";
    private static final String GROUP_NAME = "multi-partition-group";
    private static final String TOPIC_NAME = "multi-partition-topic";

    public static void main(String[] args) {

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, GROUP_NAME);

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of(TOPIC_NAME));

        Thread mainThread = Thread.currentThread();

        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            LOGGER.info("call hook");
            consumer.wakeup();

            try {
                mainThread.join();
            } catch (InterruptedException e) {
                LOGGER.info("main thread dead");
            }
        }));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000L));

                for (ConsumerRecord<String, String> record : records) {
                    LOGGER.info("topic: {}, partition: {}, offset: {}, key: {}, value: {}", record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }
                consumer.commitAsync((offsets, exception) -> {
                    if (exception != null) {
                        LOGGER.error("offsets: {} is not completed, error: {}", offsets, exception);
                    } else {
                        for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {
                            LOGGER.info("topic: {}, partition: {}, offset: {}, metadata: {}", entry.getKey().topic(), entry.getKey().partition(), entry.getValue().offset(), entry.getValue().metadata());
                        }
                    }
                });
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            consumer.close();
        }
    }
}
```

- 아래 사진을 보면 main 스레드가 죽기전에 추가적인 작업을 하는것을 볼수 있습니다.

1. 이전에 할당된 파티션을 취소합니다.
2. 코디네이터에게 LeaveGroup요청을 보내게 됩니다. (야 나 곧 죽으니까 떠날거야)
3. 정상적으로 그룹을 탈퇴하게 됩니다.
4. 그럼 코디네이터는 바로 리밸런싱 작업을 들어가게되고 나머지 2개의 Consumer는 죽은 Consumer의 파티션을 할당받아 처리하게 됩니다.

<img width="982" alt="스크린샷 2024-01-28 오후 2 12 03" src="https://github.com/kdg0209/realizers/assets/80187200/742e38b2-4ede-4a06-8805-1810a3252b72">


### 🤔 왜 Consumer는 죽은 즉시 코디네이터에게 알리지 않을까?

- 우선 Consumer는 heartbeat.interval.ms = 3000 설정에 의해 3초마다 코디네이터에게 자신이 살아있다는 것을 알립니다.
- 그리고 session.timeout.ms = 45000 설정으로 인해 45초 동안 heartbeat를 보내지 않으면 그제서야 리밸런싱이 이루어지고 다른 Consumer에 파티션을 할당하게 됩니다.

  
