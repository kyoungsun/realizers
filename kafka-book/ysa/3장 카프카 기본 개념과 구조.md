# 3장 카프카 기본 개념과 구조

# 3.1 카프카 기초 다지기

- 주피커 : 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당
- 카프카 및 카프카 클러스터 : 여러대의 브로커를 구성한 클러스터를 의미
- 브로커 : 카프카 애플리케이션이 설치된 서버 또는 노드
- 프로듀서 : 카프카로 메시지를 보내는 역할을 하는 클라이언트
- 컨슈머 : 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트
- 토픽 : 카프카는 메시지 피드들을 토픽으로 구분
- 파티션 : 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러개로 나눈 것
- 세그먼트 : 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일
- 메시지 또는 레코드 : 프로듀서가 전송하는 데이터 조각

## 3.1.1 리플리 케이션

- 각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작
- 파티션이 복제되는것
- 리플리케이션 팩터 수
    - 테스트 및 개발 환경 : 1개
    - 운영 환경(약간의 유실 허용) : 2개
    - 운영 환경(유실 허용X) : 3개

## 3.1.2 파티션

- 하나의 토픽을 여러개로 나눠 병렬처리하게 만든 것
- 나뉜 파티션 수만큼 컨슈머 연결 가능
- 파티션 번호는 0부터 시작
- 파티션을 늘리는것은 가능하지만, 줄이기는 불가능(초기 세팅을 보수적으로 할 필요)
- LAG : 프로듀서가 보낸 메시지 수(카프카에 남아있는) - 컨슈머가 가져간 메시지 수 → 메시지 지연여부 확인

## 3.1.3 세그 먼트

- 프로듀서로 전송된 메시지는 토픽의 파티션에 저장
- 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장
- 파티션이 늘어나면 디렉토리도 증가
- 순서
    - 프로듀서는 카프카의 토픽으로 메시지 전송
    - 파티션 세그먼트 로그파일에 저장
    - 브로커의 세그먼트 로그파일에 저장된 메시지는 컨슈머가 조회

# 3.2 카프카의 핵심 개념

- 카프카의 장점 : 높은 처리량, 빠른 응답 속도, 안정성

## 3.2.1 분산 시스템

- 네트워크상에서 연결된 컴퓨터들의 그룹
- 장애대응 및 시스템 확장에 용이

## 3.2.2 페이지 캐시

- 디스크 I/O 에 대한 접근을 줄이므로 성능을 높일 수 있다.
- OS 페이지 캐시와 동일한 작동 방식

## 3.2.3 배치 전송 처리

## 3.2.4 압축 전송

- 높은 압축률 :  gzip, zstd
- 빠른 응답속도 : lz4, snappy

## 3.2.5 토픽, 파티션, 오프셋

- 오프셋 : 파티션의 메시지가 저장되는 위치
- 오프셋을 통해 메시지의 순서를 보장(오프셋은 순차적으로 증가)

## 3.2.6 고가용성 보장

- 하나의 서버 또는 노드가 장애가 발생해도 안정적인 서비스 가능
- 리플리케이션 기능을 통해 보장
- 원본(리더), 리플리케이션(팔로워)
- 힝싱 리더의 숫자는 1을 유지
- 모든 읽기/쓰기는 리더에서만 이뤄진다.

## 3.2.7 주키퍼의 의존성

- 하둡, 나이파이, 에이치베이스
- 주피커는 앙상블로 구성하고, 살아있는 노드가 과반수 이상이면 정상적으로 실행된다.
- 주피커는 항상 홀수
- 주피커 : 카프카의 메타데이터를 저장하고 각 브로커를 관리하는 역할

# 프로듀서의 기본 동작과 예제 맛보기

- 레코드 : 토픽(required), 파티션(optional), 키(optional), 밸류(required)
- 파티션을 지정하지 않은 경우 파티셔너가 라운드로빈 방식으로 파티션 선택에서 레코드 전달
- 파티션별로 레코드 잠시 저장 후 → 배치 전송

## 예제

```yaml
version: "3.5"
services:
  zk:
    image: confluentinc/cp-zookeeper:5.5.1
    restart: always
    hostname: zk
    container_name: zk
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_SERVER_ID=1
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk:2888:3888

  kafka:
    image: confluentinc/cp-kafka:5.5.1
    restart: always
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9999:9999"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zk:2181
      KAFKA_LISTENERS: INTERNAL://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9999

  kafka_manager:
    image: hlebalbau/kafka-manager:stable
    container_name: cmak
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: "zk:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
```

```plain text
# Kafka 설정 변수
KAFKA_BROKER_ID: 유일값이어야함 (중복X)
KAFKA_ZOOKEEPER_CONNECT: zookeeper
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 트랜잭션 상태에서 복제 수
KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 트랜잭션 최소 ISR(InSyncReplicas 설정) 수

#도커 내부가 아닌 외부에서 접속시 변경 필요
KAFKA_ADVERTISED_LISTENERS: 외부에서 접속용 리스너 설정
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 보안을 위한 프로토콜 매핑. 여기 설정 값이 KAFKA_ADVERTISED_LISTENERS 과 함께 key-value로 매핑
KAFKA_INTER_BROKER_LISTENER_NAME: 도커 내부에서 리스너 이름을 지정
```

```bash
docker exec -it <프로듀서_컨테이너_이름> 
kafka-topics --bootstrap-server kafka:9092 --create --topic peter-basic01 -partitions 1 --replication-factor 1
kafka-console-consumer --bootstrap-server kafka:9092 --topic peter-basic01
kafka-console-producer --bootstrap-server kafka:9092 --topic peter-basic01

```

### 예제 3-1) 메시지 전송 후 잘 받았는지 확인하지 않은 예제

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerFireForgot {
	private static final String BOOTSTRAP_SERVERS_CONFIG = "local_machine_ip:9092";
	private static final String TOPIC = "peter-basic01";
        
		public static void main(String[] args) {
			Properties props = new Properties();
			props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG); //브로커 리스트를 정의합니다.
            //메시지 키와 벨류에 문자열을 지정해야하므로 StringSerializer를 지정합니다.
            props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); 
            props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
				
			//Properties 오브젝트를 전달해 새 프로듀서를 생성
            Producer<String, String> producer = new KafkaProducer<>(props);

        try {
            for (int i = 0; i < 3; i++) {
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "Apache Kafka is a distributed streaming platform - " + i); //ProducerRecord 오브젝트를 생성합니다.
                producer.send(record); //send()메소드를 사용하여 메시지를 전송(메시지 전송결과는 확인 하지 않음)
            }
        } catch (Exception e){
            e.printStackTrace(); // 해당에러는 전송 전 에러가 발생
        } finally {
            producer.close(); // 프로듀서 종료
        }
    }
}
```

### 예제 3-2) 동기전송

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerSync {
    private static final String BOOTSTRAP_SERVERS_CONFIG = "local_machine_ip:9092";
    private static final String TOPIC = "peter-basic01";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        Producer<String, String> producer = new KafkaProducer<>(props);
        try {
            for (int i = 0; i < 3; i++) {
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "Apache Kafka is a distributed streaming platform - " + i); //ProducerRecord 오브젝트를 생성합니다.
                RecordMetadata metadata = producer.send(record).get(); //get() 메소드를 이용해 카프카의 응답을 기다립니다.
                System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", metadata.topic(), metadata.partition()
                        , metadata.offset(), record.key(), record.value());
            }
        } catch (Exception e){
            e.printStackTrace(); //카프카로 메시지를 보내기 전과 보내는 동안 에러가 발생하면 예외가 발생합니다.
        } finally {
            producer.close(); // 프로듀서 종료
        }
    }
}
```

### 예제 3-3) 비동기 전송을 위한 콜백 class

```java
public class PeterProducerCallback implements Callback { //콜백을 사용하기 위해 org.apache.kafka.clients.producer.Callback를 구현하는 클래스가 필요합니다.
    private ProducerRecord<String, String> record;

    public PeterProducerCallback(ProducerRecord<String, String> record) {
        this.record = record;
    }

    @Override
    public void onCompletion(RecordMetadata metadata, Exception e) {
        if (e != null) {
            e.printStackTrace();
        } else {
            System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", metadata.topic(), metadata.partition()
                    , metadata.offset(), record.key(), record.value());
        }
    }
}
```

### 예제 3-4) 비동기 전송

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerAsync {
    private static final String BOOTSTRAP_SERVERS_CONFIG = "local_machine_ip:9092";
    private static final String TOPIC = "peter-basic01";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        Producer<String, String> producer = new KafkaProducer<>(props);

        try {
            for (int i = 0; i < 3; i++) {
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "Apache Kafka is a distributed streaming platform - " + i); //ProducerRecord 오브젝트를 생성합니다.
	              //프로듀서에서 레코드를 보낼 때 콜백 객체를 함께 전송
								//콜백 함수에서 콜백 받음 (PeterProducerCallback.onCompletion)
								producer.send(record, new PeterProducerCallback(record)); 
            }
        } catch (Exception e){
            e.printStackTrace();
        } finally {
            producer.close(); // 프로듀서 종료
        }
    }
}
```

# 3.4 컨슈머의 기본 동작과 예제 맛보기

## 3.4.1 컨슈머의 기본 동작

1. 메시지를 전송한 후 브로커들의 로컬 디스크에 저장
2. 컨슈머를 통해 메시지 조회
- 컨슈머의 수와 파티션의 수가 일치하는 것이 이상적 (컨슈머가 더 많으면 X, 리소스 낭비)

## 예제

### 예제 3-5) 오토 커밋

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Arrays;
import java.util.Properties;

public class ConsumerAuto {
    private static final String BOOTSTRAP_SERVERS_CONFIG = "local_machine_ip:9092";
    private static final String TOPIC = "peter-basic01";
    private static final String CONSUMER_GROUP = "groupname";
    private static final boolean AUTO_COMMIT =true;

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, AUTO_COMMIT); //자동 커밋을 사용
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props); 
        consumer.subscribe(Arrays.asList(TOPIC)); //구독할 토픽을 지정

        try {
            while (true) { //메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
                ConsumerRecords<String, String> records = consumer.poll(1000);
                for (ConsumerRecord<String, String> record : records) { //poll()은 레코드 전체를 리턴
                    System.out.printf("Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                            record.topic(), record.partition(), record.offset(), record.key(), record.value());
                }
            }
        } catch (Exception e){
            e.printStackTrace();
        } finally {
            consumer.close(); //컨슈머를 종료합니다.
        }
    }
}
```

### 예제 3-6) 동기 가져오기

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Arrays;
import java.util.Properties;

public class ConsumerAuto {
    private static final String BOOTSTRAP_SERVERS_CONFIG = "local_machine_ip:9092";
    private static final String TOPIC = "peter-basic01";
    private static final String CONSUMER_GROUP = "groupname";
    private static final boolean AUTO_COMMIT = false;
		private static final String LATEST = "latest";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, AUTO_COMMIT); //자동 커밋을 사용
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, LATEST); //오프셋을 찾지 못한경우, 가장 최근 메시지부터 가져오도록 설정
				KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props); 
        consumer.subscribe(Arrays.asList(TOPIC)); //구독할 토픽을 지정

        try {
            while (true) { //메시지를 가져오기 위해 카프카에 지속적으로 poll()
                ConsumerRecords<String, String> records = consumer.poll(1000);
                for (ConsumerRecord<String, String> record : records) { //poll()은 레코드 전체를 리턴
                    System.out.printf("Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                            record.topic(), record.partition(), record.offset(), record.key(), record.value());
								}
                consumer.commitSync();
            }
        } catch (Exception e){
            e.printStackTrace();
        } finally {
            consumer.close(); //컨슈머를 종료합니다.
        }
    }
}
```

### 예제 3-7) 비동기 가져오기

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Arrays;
import java.util.Properties;

public class ConsumerAuto {
    private static final String BOOTSTRAP_SERVERS_CONFIG = "local_machine_ip:9092";
    private static final String TOPIC = "peter-basic01";
    private static final String CONSUMER_GROUP = "groupname";
    private static final boolean AUTO_COMMIT = false;
		private static final String LATEST = "latest";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, AUTO_COMMIT); //자동 커밋을 사용
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, LATEST); //오프셋을 찾지 못한경우, 가장 최근 메시지부터 가져오도록 설정
				KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props); 
        consumer.subscribe(Arrays.asList(TOPIC)); //구독할 토픽을 지정

        try {
            while (true) { //메시지를 가져오기 위해 카프카에 지속적으로 poll()
                ConsumerRecords<String, String> records = consumer.poll(1000);
                for (ConsumerRecord<String, String> record : records) { //poll()은 레코드 전체를 리턴
                    System.out.printf("Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                            record.topic(), record.partition(), record.offset(), record.key(), record.value());
								}
                consumer.commitASync();
            }
        } catch (Exception e){
            e.printStackTrace();
        } finally {
            consumer.close(); //컨슈머를 종료합니다.
        }
    }
}
```

## 3.4.4 컨슈머 그룹의 이해

- 컨슈머 그룹안에 여러개의 컨슈머 구성
- 그룹내 컨슈머 그룹은 서로 정보 공유 :  장애가 생기면 다른 컨슈머가 이를 대신해 컨슘