# 3장 카프카 기본 개념과 구조

# 3.1 카프카 기초 다지기

- 주피커 : 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당
- 카프카 및 카프카 클러스터 : 여러대의 브로커를 구성한 클러스터를 의미
- 브로커 : 카프카 애플리케이션이 설치된 서버 또는 노드
- 프로듀서 : 카프카로 메시지를 보내는 역할을 하는 클라이언트
- 컨슈머 : 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트
- 토픽 : 카프카는 메시지 피드들을 토픽으로 구분
- 파티션 : 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러개로 나눈 것
- 세그먼트 : 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일
- 메시지 또는 레코드 : 프로듀서가 전송하는 데이터 조각

## 3.1.1 리플리 케이션

- 각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작
- 파티션이 복제되는것
- 리플리케이션 팩터 수
    - 테스트 및 개발 환경 : 1개
    - 운영 환경(약간의 유실 허용) : 2개
    - 운영 환경(유실 허용X) : 3개

## 3.1.2 파티션

- 하나의 토픽을 여러개로 나눠 병렬처리하게 만든 것
- 나뉜 파티션 수만큼 컨슈머 연결 가능
- 파티션 번호는 0부터 시작
- 파티션을 늘리는것은 가능하지만, 줄이기는 불가능(초기 세팅을 보수적으로 할 필요)
- LAG : 프로듀서가 보낸 메시지 수(카프카에 남아있는) - 컨슈머가 가져간 메시지 수 → 메시지 지연여부 확인

## 3.1.3 세그 먼트

- 프로듀서로 전송된 메시지는 토픽의 파티션에 저장
- 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장
- 파티션이 늘어나면 디렉토리도 증가
- 순서
    - 프로듀서는 카프카의 토픽으로 메시지 전송
    - 파티션 세그먼트 로그파일에 저장
    - 브로커의 세그먼트 로그파일에 저장된 메시지는 컨슈머가 조회

# 3.2 카프카의 핵심 개념

- 카프카의 장점 : 높은 처리량, 빠른 응답 속도, 안정성

## 3.2.1 분산 시스템

- 네트워크상에서 연결된 컴퓨터들의 그룹
- 장애대응 및 시스템 확장에 용이

## 3.2.2 페이지 캐시

- 디스크 I/O 에 대한 접근을 줄이므로 성능을 높일 수 있다.
- OS 페이지 캐시와 동일한 작동 방식

## 3.2.3 배치 전송 처리

## 3.2.4 압축 전송

- 높은 압축률 :  gzip, zstd
- 빠른 응답속도 : lz4, snappy

## 3.2.5 토픽, 파티션, 오프셋

- 오프셋 : 파티션의 메시지가 저장되는 위치
- 오프셋을 통해 메시지의 순서를 보장(오프셋은 순차적으로 증가)

## 3.2.6 고가용성 보장

- 하나의 서버 또는 노드가 장애가 발생해도 안정적인 서비스 가능
- 리플리케이션 기능을 통해 보장
- 원본(리더), 리플리케이션(팔로워)
- 힝싱 리더의 숫자는 1을 유지
- 모든 읽기/쓰기는 리더에서만 이뤄진다.

## 3.2.7 주키퍼의 의존성

- 하둡, 나이파이, 에이치베이스
- 주피커는 앙상블로 구성하고, 살아있는 노드가 과반수 이상이면 정상적으로 실행된다.
- 주피커는 항상 홀수
- 주피커 : 카프카의 메타데이터를 저장하고 각 브로커를 관리하는 역할

# 프로듀서의 기본 동작과 예제 맛보기

- 레코드 : 토픽(required), 파티션(optional), 키(optional), 밸류(required)
- 파티션을 지정하지 않은 경우 파티셔너가 라운드로빈 방식으로 파티션 선택에서 레코드 전달
- 파티션별로 레코드 잠시 저장 후 → 배치 전송

## 예제

```yaml
version: '3.5'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.1
    #    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper
    restart: always
    environment:
      # 주피커 식별 ID : 동일 클러스터 내에서 중복되면 안됨
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      # 클러스터 구성시 동기화를 위한 기본 틱 타임(ms)
      ZOOKEEPER_TICK_TIME: 2000
      # 주키퍼 초기화를 위한 제한 시간
      # 마스터 선출을 위해 주피커들이 리더에 커넥션을 맺을때 지정할 초기 타임 아웃 시간
      # Zookeeper Tick TIme * Zookeeper Init Time
      # 멀티 브로커에서 유효한 속성
      ZOOKEEPER_INIT_LIMIT: 5
      # 주키퍼 리더와 나머지 서버들의 싱크 타임
      # 시간 내 싱크응답이 들어오는 경우 클러스터가 정상으로 구성됨을 확인
      #Zookeeper Tick TIme * Zookeeper Sync Limit
      # 멀티 브로커에서 유효한 속성
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "22181:2181"
  kafka:
    image: confluentinc/cp-kafka:5.5.1
    restart: always
    # 서비스 우선순위 지정 : zookeeper가 먼저 실행되어있어야 해당 컨테이너 실행
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      # kafka 브로커 아이디 지정
      KAFKA_BROKER_ID: 1
      # 주키퍼에 커넥션하기 위한 대상 지정
      # zookeeper(서비스이름):2181(내부컨테이너포트)
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      # 외부에서 접속하기 위한 리스너 설정
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      #도커 내부에서 사용할 리스너 이름
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      #single 브로커인 경우 1로 설정 필요, 멀티 브로커인 경우 기본값사용하므로 설정 필요 X
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # 컨슈머들이 컨슈머그룹에 조인할 때 대기시간
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
```

```bash
docker exec -it <프로듀서_컨테이너_이름> 
kafka-topics --bootstrap-server kafka:9092 --create --topic peter-basic01 -partitions 1 --replication-factor 1
kafka-console-consumer --bootstrap-server kafka:9092 --topic peter-basic01
kafka-console-producer --bootstrap-server kafka:9092 --topic peter-basic01
```

### 예제 3-1) 메시지 전송 후 잘 받았는지 확인하지 않은 예제

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerFireForgot {
  private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:29092";
  private static final String TOPIC = "peter-basic02";

  public static void main(String[] args) {
    Properties props = new Properties(); //Properties 오브젝트를 시작합니다.
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG); //브로커 리스트를 정의합니다.
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); //메시지 키와 벨류에 문자열을 지정하므로 내장된 StringSerializer를 지정합니다.
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    Producer<String, String> producer = new KafkaProducer<>(props); //Properties 오브젝트를 전달해 새 프로듀서를 생성합니다.

    try {
      for (int i = 0; i < 3; i++) {
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "Apache Kafka is a distributed streaming platform - " + i); //ProducerRecord 오브젝트를 생성합니다.
        producer.send(record); //send()메소드를 사용하여 메시지를 전송 후 Java Future Ojbect로 RecordMetadata를 리턴 받지만, 리턴값을 무시하므로 메시지가 성공적으로 전송되었는지 알 수 없습니다.
      }
    } catch (Exception e){
      e.printStackTrace(); //카프카 브로커에게 메시지를 전송한 후의 에러는 무시하지만, 전송 전 에러가 발생하면 예외를 처리할 수 있습니다.
    } finally {
      producer.close(); // 프로듀서 종료
    }
  }
}
```

### 예제 3-2) 동기전송

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerSync {
  private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:29092";
  private static final String TOPIC = "peter-basic02";

  public static void main(String[] args) {
    Properties props = new Properties();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());


    Producer<String, String> producer = new KafkaProducer<>(props);
    try {
      while (true) {
        for (int i = 0; i < 3; i++) {
          ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "Apache Kafka is a distributed streaming platform - " + i); //ProducerRecord 오브젝트를 생성합니다.
          RecordMetadata metadata = producer.send(record).get();//get() 메소드를 이용해 카프카의 응답을 기다립니다. 메시지가 성공적으로 전송되지 않으면 예외가 발생하고, 에러가 없다면 RecordMetadata를 얻게 됩니다.
          System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", metadata.topic(), metadata.partition()
                  , metadata.offset(), record.key(), record.value());
          Thread.sleep(3000);
        }
      }
    } catch (Exception e){
      e.printStackTrace(); //카프카로 메시지를 보내기 전과 보내는 동안 에러가 발생하면 예외가 발생합니다.
    } finally {
      producer.close(); // 프로듀서 종료
    }
    //Thread.sleep(8000);
  }
}
```

### 예제 3-3) 비동기 전송을 위한 콜백 class

```java
public class PeterProducerCallback implements Callback { //콜백을 사용하기 위해 org.apache.kafka.clients.producer.Callback를 구현하는 클래스가 필요합니다.
    private ProducerRecord<String, String> record;

    public PeterProducerCallback(ProducerRecord<String, String> record) {
        this.record = record;
    }

    @Override
    public void onCompletion(RecordMetadata metadata, Exception e) {
        if (e != null) {
            e.printStackTrace();
        } else {
            System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", metadata.topic(), metadata.partition()
                    , metadata.offset(), record.key(), record.value());
        }
    }
}
```

### 예제 3-4) 비동기 전송

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerAsync {
  private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:29092";
  private static final String TOPIC = "peter-basic02";

  public static void main(String[] args) {
    Properties props = new Properties();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    Producer<String, String> producer = new KafkaProducer<>(props);

    try {
      for (int i = 0; i < 3; i++) {
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "Apache Kafka is a distributed streaming platform - " + i); //ProducerRecord 오브젝트를 생성합니다.
        producer.send(record, new PeterProducerCallback(record));
        //프로듀서에서 레코드를 보낼 때 콜백 오브젝트를 같이 보냅니다.
      }
    } catch (Exception e){
      e.printStackTrace();
    } finally {
      producer.close(); // 프로듀서 종료
    }
  }
}
```

# 3.4 컨슈머의 기본 동작과 예제 맛보기

## 3.4.1 컨슈머의 기본 동작

1. 메시지를 전송한 후 브로커들의 로컬 디스크에 저장
2. 컨슈머를 통해 메시지 조회
- 컨슈머의 수와 파티션의 수가 일치하는 것이 이상적 (컨슈머가 더 많으면 X, 리소스 낭비)

## 예제

### 예제 3-5) 오토 커밋

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Arrays;
import java.util.Properties;

public class ConsumerAuto {
  private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:29092";
  private static final String TOPIC = "peter-basic02";
  private static final String CONSUMER_GROUP = "test";
  private static final boolean AUTO_COMMIT = true;

  public static void main(String[] args) {
    Properties props = new Properties();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

    props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, AUTO_COMMIT); //자동 커밋을 사용합니다.

    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props); //Properties 오브젝트를 전달하여 새 컨슈머를 생성합니다.
    consumer.subscribe(Arrays.asList(TOPIC)); //구독할 토픽을 지정합니다.


    try {
      while (true) { //무한 루프 시작입니다. 메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
        ConsumerRecords<String, String> records = consumer.poll(4000); //컨슈머는 폴링하는 것을 계속 유지하며, 타임 아웃 주기를 설정합니다.해당 시간만큼 블럭합니다.
        for (ConsumerRecord<String, String> record : records) { //poll()은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로, 반복문 처리합니다.
          System.out.printf("Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                  record.topic(), record.partition(), record.offset(), record.key(), record.value());
        }
      }
    } catch (Exception e){
      e.printStackTrace();
    } finally {
      consumer.close(); //컨슈머를 종료합니다.
    }
  }
}
```

### 예제 3-6) 동기 가져오기

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Arrays;
import java.util.Properties;

public class ConsumerSync {
  private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:29092";
  private static final String TOPIC = "peter-basic02";
  private static final String CONSUMER_GROUP = "test";
  private static final boolean AUTO_COMMIT = false;

  public static void main(String[] args) {
    Properties props = new Properties();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");
    props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, AUTO_COMMIT); //자동 커밋을 사용합니다.
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props); //Properties 오브젝트를 전달하여 새 컨슈머를 생성합니다.
    consumer.subscribe(Arrays.asList(TOPIC)); //구독할 토픽을 지정합니다.

    try {
      while (true) { //무한 루프 시작입니다. 메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
        ConsumerRecords<String, String> records = consumer.poll(3000); //컨슈머는 폴링하는 것을 계속 유지하며, 타임 아웃 주기를 설정합니다.해당 시간만큼 블럭합니다.
        for (ConsumerRecord<String, String> record : records) { //poll()은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로, 반복문 처리합니다.
          System.out.printf("Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                  record.topic(), record.partition(), record.offset(), record.key(), record.value());
        }
        consumer.commitSync(); //현재 배치를 통해 읽은 모든 메시지들을 처리한 후, 추가 메시지를 폴링하기 전 현재의 오프셋을 커밋합니다.
      }
    } catch (Exception e){
      e.printStackTrace();
    } finally {
      consumer.close(); //컨슈머를 종료합니다.
    }
  }
}
```

### 예제 3-7) 비동기 가져오기

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Arrays;
import java.util.Properties;

public class ConsumerAsync {
  private static final String BOOTSTRAP_SERVERS_CONFIG = "localhost:29092";
  private static final String TOPIC = "peter-basic02";
  private static final String CONSUMER_GROUP = "test";
  private static final boolean AUTO_COMMIT = false;

  public static void main(String[] args) {
    Properties props = new Properties();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS_CONFIG);
    props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, AUTO_COMMIT); //자동 커밋을 사용하지 않습니다.
    props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest"); //컨슈머 오프셋을 찾지 못하는 경우 latest로 초기화 합니다. 가장 최근부터 메시지를 가져오게 됩니다.
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props); 
    consumer.subscribe(Arrays.asList(TOPIC)); 

    try {
      while (true) { //무한 루프 시작입니다. 메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
        ConsumerRecords<String, String> records = consumer.poll(1000); //컨슈머는 폴링하는 것을 계속 유지하며, 타임 아웃 주기를 설정합니다.해당 시간만큼 블럭합니다.
        for (ConsumerRecord<String, String> record : records) { //poll()은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로, 반복문 처리합니다.
          System.out.printf("Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                  record.topic(), record.partition(), record.offset(), record.key(), record.value());
        }
        consumer.commitAsync(); //현재 배치를 통해 읽은 모든 메시지들을 처리한 후, 추가 메시지를 폴링하기 전 현재의 오프셋을 비동기 커밋합니다.
      }
    } catch (Exception e){
      e.printStackTrace();
    } finally {
      consumer.close(); //컨슈머를 종료합니다.
    }
  }
}
```

## 3.4.4 컨슈머 그룹의 이해

- 컨슈머 그룹안에 여러개의 컨슈머 구성
- 그룹내 컨슈머 그룹은 서로 정보 공유 :  장애가 생기면 다른 컨슈머가 이를 대신해 컨슘